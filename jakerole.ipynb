{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"1751b6ecc16a4fb4868c3bc220aa58ea":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_201760115afc4573a7a13367781c7d6f","IPY_MODEL_1ab579f2fc8d4407b022ae7c80a9bf53","IPY_MODEL_2652d06548fe46958f77302ed3d64d91"],"layout":"IPY_MODEL_7147e7131f3349ef934e531703759a98"}},"201760115afc4573a7a13367781c7d6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_716f9f452193463dbc5897c92689b346","placeholder":"​","style":"IPY_MODEL_9ae5b7f451804da2bc4c4720493f6c5a","value":"Loading checkpoint shards: 100%"}},"1ab579f2fc8d4407b022ae7c80a9bf53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_792eb627c0e94492b940a5d011963fe5","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25f97933aad94586b99364758a9dc7cd","value":2}},"2652d06548fe46958f77302ed3d64d91":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_664773f6c920486c8497147c132c224b","placeholder":"​","style":"IPY_MODEL_641f2a3f898a4402a1ef5216da911317","value":" 2/2 [01:01&lt;00:00, 28.04s/it]"}},"7147e7131f3349ef934e531703759a98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"716f9f452193463dbc5897c92689b346":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae5b7f451804da2bc4c4720493f6c5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"792eb627c0e94492b940a5d011963fe5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25f97933aad94586b99364758a9dc7cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"664773f6c920486c8497147c132c224b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"641f2a3f898a4402a1ef5216da911317":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"967f506f67784aa8854f3930dd8a942f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f4636029a3041f6a2730c86b050b176","IPY_MODEL_834f7c0110e14273923d69eea3eaaa6b","IPY_MODEL_9b36aa3b4b0b47d98021224f832df7e3"],"layout":"IPY_MODEL_c890a9a4f8e14c338f70c9a1894d57ec"}},"4f4636029a3041f6a2730c86b050b176":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2483174f0270429baa6686719ff82db6","placeholder":"​","style":"IPY_MODEL_be4b94a5be954b80afe07cc4b7692e62","value":"pytorch_model-00002-of-00002.bin: 100%"}},"834f7c0110e14273923d69eea3eaaa6b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cf14735b7934b19ab7405810fa45d6e","max":3500317102,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e8cd2b521861457681ccc4bfc80101fa","value":3500317102}},"9b36aa3b4b0b47d98021224f832df7e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fc257c8ec1049eb9422069c3b00422c","placeholder":"​","style":"IPY_MODEL_d7435d16ee404031aae8c59d0df73980","value":" 3.50G/3.50G [02:42&lt;00:00, 26.5MB/s]"}},"c890a9a4f8e14c338f70c9a1894d57ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2483174f0270429baa6686719ff82db6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be4b94a5be954b80afe07cc4b7692e62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6cf14735b7934b19ab7405810fa45d6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8cd2b521861457681ccc4bfc80101fa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8fc257c8ec1049eb9422069c3b00422c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7435d16ee404031aae8c59d0df73980":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f54d458f9ca450383b01373539c2929":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d59b25f9519640a28dda22056558f85a","IPY_MODEL_e2b667d720444c189d4e9966898ae700","IPY_MODEL_4e2f769a79e74f7baf41e0388838117e"],"layout":"IPY_MODEL_09452cff173f45fe9e147acec344f71f"}},"d59b25f9519640a28dda22056558f85a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ffb63e6404844e29cd82163f1231042","placeholder":"​","style":"IPY_MODEL_2eb48c542db94fa3ac11575750907684","value":"Upload 2 LFS files: 100%"}},"e2b667d720444c189d4e9966898ae700":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b77b066a7e946b0b210b73658c58656","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d19bd27c95d54ef7a501c550065faafa","value":2}},"4e2f769a79e74f7baf41e0388838117e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_803ac263f7724e3db3ebf2ff75a9c7ef","placeholder":"​","style":"IPY_MODEL_bcfc173c770943ebb12f9e8403edda8a","value":" 2/2 [07:11&lt;00:00, 224.96s/it]"}},"09452cff173f45fe9e147acec344f71f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ffb63e6404844e29cd82163f1231042":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2eb48c542db94fa3ac11575750907684":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b77b066a7e946b0b210b73658c58656":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d19bd27c95d54ef7a501c550065faafa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"803ac263f7724e3db3ebf2ff75a9c7ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcfc173c770943ebb12f9e8403edda8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6ea7efc6e4c4ff9bc3916e80ae8e484":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a9165b4ae2ba45f6b232f640b864addf","IPY_MODEL_f3b3c49aff434a08a8d84fd91f21a243","IPY_MODEL_3f73f7a6d1d74f3ab85dc5be08dbd9ea"],"layout":"IPY_MODEL_5316ff5e03574e609e989a7343b5d985"}},"a9165b4ae2ba45f6b232f640b864addf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9971ee52aa104344b9e0fb4d6027ea48","placeholder":"​","style":"IPY_MODEL_5d8eb62fdbc14bd8b84ada150f3c4c17","value":"pytorch_model-00001-of-00002.bin: 100%"}},"f3b3c49aff434a08a8d84fd91f21a243":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c49f4a02322488cb1455b8759b78587","max":9976638373,"min":0,"orientation":"horizontal","style":"IPY_MODEL_431e63c57b8a48d0a443f7264ffcd12a","value":9976638373}},"3f73f7a6d1d74f3ab85dc5be08dbd9ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8394aae7eec4eb88b273e6a9ebe2627","placeholder":"​","style":"IPY_MODEL_5228c61bb6cf47ad9ae01b9ae5e424b2","value":" 9.98G/9.98G [07:10&lt;00:00, 23.2MB/s]"}},"5316ff5e03574e609e989a7343b5d985":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9971ee52aa104344b9e0fb4d6027ea48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d8eb62fdbc14bd8b84ada150f3c4c17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c49f4a02322488cb1455b8759b78587":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"431e63c57b8a48d0a443f7264ffcd12a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8394aae7eec4eb88b273e6a9ebe2627":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5228c61bb6cf47ad9ae01b9ae5e424b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd24de75203c49198775c1b0ee827f83":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c2d05c7246546a09dce6c39b1e9243b","IPY_MODEL_6a2f5946b7c14314af5bcce41e7b8409","IPY_MODEL_b1da779db8c7402f93225daf460206a8"],"layout":"IPY_MODEL_6fb78df980564d5e80cb434abf51620c"}},"2c2d05c7246546a09dce6c39b1e9243b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c0106d2f8a4427e912dbf2169a25861","placeholder":"​","style":"IPY_MODEL_058cf70fe9f2432a9539912120b2eb9b","value":"Saving the dataset (1/1 shards): 100%"}},"6a2f5946b7c14314af5bcce41e7b8409":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_55e16ffec88f4fa89fb8c194b5b7033e","max":250,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2ab9186a6e9403fae54dedca0a25858","value":250}},"b1da779db8c7402f93225daf460206a8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_11e1a2aff8124c75bd9d4a2bf71f0b68","placeholder":"​","style":"IPY_MODEL_b87f415fcc5b444c9746eabd1e183c38","value":" 250/250 [00:00&lt;00:00, 4505.39 examples/s]"}},"6fb78df980564d5e80cb434abf51620c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c0106d2f8a4427e912dbf2169a25861":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"058cf70fe9f2432a9539912120b2eb9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55e16ffec88f4fa89fb8c194b5b7033e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2ab9186a6e9403fae54dedca0a25858":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"11e1a2aff8124c75bd9d4a2bf71f0b68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b87f415fcc5b444c9746eabd1e183c38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a4d3ebef9824382a735af06ebec0e84":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4bb0d453f5f54c709b5514d682fe1bd1","IPY_MODEL_869798cf28d2456fbce931fa9bd64512","IPY_MODEL_81231c95170d47adac2086110c27c5b2"],"layout":"IPY_MODEL_bbde9c9273624346a412e04e680473cd"}},"4bb0d453f5f54c709b5514d682fe1bd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c02773f7a28e4fcd928f526d068c0362","placeholder":"​","style":"IPY_MODEL_353bbfa82f494d3ea4f4dbf1cc689150","value":"Loading checkpoint shards: 100%"}},"869798cf28d2456fbce931fa9bd64512":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_329632d9047e455fa673d15a0270987a","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e84a683dbb7f4e00831a28e337552c3e","value":2}},"81231c95170d47adac2086110c27c5b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32d345c90f8747d3b8d7b1431e8568ac","placeholder":"​","style":"IPY_MODEL_f9318e9b3c594b80a4e8eb805cb5d1c2","value":" 2/2 [00:57&lt;00:00, 26.10s/it]"}},"bbde9c9273624346a412e04e680473cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c02773f7a28e4fcd928f526d068c0362":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"353bbfa82f494d3ea4f4dbf1cc689150":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"329632d9047e455fa673d15a0270987a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e84a683dbb7f4e00831a28e337552c3e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"32d345c90f8747d3b8d7b1431e8568ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9318e9b3c594b80a4e8eb805cb5d1c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"535b5c4819374d2d897aae06d3a6e17e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_076758d6cbd143659c6c8ab6313cf24f","IPY_MODEL_f710a18db1df40d1b7174614953570cb","IPY_MODEL_ca7a5575976f4c7baf9f0eaec0cba4ce"],"layout":"IPY_MODEL_5fc2b4922b1d413698e9cbe306018892"}},"076758d6cbd143659c6c8ab6313cf24f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4547a6b2150d4e2dbd90fc0f9654286c","placeholder":"​","style":"IPY_MODEL_e9351e66c1234a32b16455cf8fdc7787","value":"Map: 100%"}},"f710a18db1df40d1b7174614953570cb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef99c1bd2fbe405c9508aea879e83a53","max":250,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2f9c498b9324d72b8b492c5f811c9e6","value":250}},"ca7a5575976f4c7baf9f0eaec0cba4ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_649be54afb1f4c01a04ddf83506fcf21","placeholder":"​","style":"IPY_MODEL_69cf611572b74448afcbeec773bebd3c","value":" 250/250 [00:00&lt;00:00, 2408.32 examples/s]"}},"5fc2b4922b1d413698e9cbe306018892":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4547a6b2150d4e2dbd90fc0f9654286c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9351e66c1234a32b16455cf8fdc7787":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef99c1bd2fbe405c9508aea879e83a53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2f9c498b9324d72b8b492c5f811c9e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"649be54afb1f4c01a04ddf83506fcf21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69cf611572b74448afcbeec773bebd3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a4522c471494de5b808c5dc0f46857a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85b350c17912470aa8089c84b2830de9","IPY_MODEL_8cd4ddfc3c5442ad97e952299ab80fa3","IPY_MODEL_ec9c8ec487024b22a66131a6c5fa8f08"],"layout":"IPY_MODEL_88ccc7ea62464d6987b205e135040144"}},"85b350c17912470aa8089c84b2830de9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c42e25104c85432e954f96761194d6ea","placeholder":"​","style":"IPY_MODEL_dc2b4dfa085f4863b2d5bcaec0020e6c","value":"Saving the dataset (1/1 shards): 100%"}},"8cd4ddfc3c5442ad97e952299ab80fa3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d03ad70643694744b2b42dfa59d94976","max":258,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c839f66b518b42b4897f09b103d77af3","value":258}},"ec9c8ec487024b22a66131a6c5fa8f08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_106ef8bc620d4e168b1dc9f8a0e5ed38","placeholder":"​","style":"IPY_MODEL_ce0b2cbea5af4869b0a9565fd1d02a38","value":" 258/258 [00:00&lt;00:00, 7266.67 examples/s]"}},"88ccc7ea62464d6987b205e135040144":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c42e25104c85432e954f96761194d6ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc2b4dfa085f4863b2d5bcaec0020e6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d03ad70643694744b2b42dfa59d94976":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c839f66b518b42b4897f09b103d77af3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"106ef8bc620d4e168b1dc9f8a0e5ed38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce0b2cbea5af4869b0a9565fd1d02a38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0098d4ba06534ae987034459a6dc38b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0647d3baae61493e801feb5db1a6e768","IPY_MODEL_bf64c7b37ec74a5a8aa49227bd36f28c","IPY_MODEL_5b235119d1864c20925f680810f2b217"],"layout":"IPY_MODEL_89fb2ca45d4e431590db1c0683e85d4d"}},"0647d3baae61493e801feb5db1a6e768":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8437ba15f234403a218116f5a3f6390","placeholder":"​","style":"IPY_MODEL_fe1f505484af42b6ae4b90b938ba9cc5","value":"Loading checkpoint shards: 100%"}},"bf64c7b37ec74a5a8aa49227bd36f28c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88dcee36007d4cf7b768228be952e26f","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_17a48c1a34da4ff49c975e97e8e9b332","value":2}},"5b235119d1864c20925f680810f2b217":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7445003d60a74aecac67d707121c2119","placeholder":"​","style":"IPY_MODEL_ba77a9eb5ac74c87acf64b9eedbd9c8d","value":" 2/2 [00:58&lt;00:00, 26.84s/it]"}},"89fb2ca45d4e431590db1c0683e85d4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8437ba15f234403a218116f5a3f6390":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe1f505484af42b6ae4b90b938ba9cc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88dcee36007d4cf7b768228be952e26f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17a48c1a34da4ff49c975e97e8e9b332":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7445003d60a74aecac67d707121c2119":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba77a9eb5ac74c87acf64b9eedbd9c8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab7bebbafd4645b8920a47f7c9fe90e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a31ba472ddaa44d18b8c530214ef6047","IPY_MODEL_236b9d6ff3d94239b07eec49387d7483","IPY_MODEL_8de106bd564b4a548c95453992e8b035"],"layout":"IPY_MODEL_d9582e8c264643e2a163718896e4a3fb"}},"a31ba472ddaa44d18b8c530214ef6047":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e95b098a6534bf69b21afa562ec4d32","placeholder":"​","style":"IPY_MODEL_7471550d17004e4a92c6e9cc60d8bfbd","value":"Map: 100%"}},"236b9d6ff3d94239b07eec49387d7483":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_166db31ca4cc4fae993bfde156173c72","max":258,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8d460300bf547f08802b12bf52d08ec","value":258}},"8de106bd564b4a548c95453992e8b035":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce6c5be64de84664a781aa79824af469","placeholder":"​","style":"IPY_MODEL_117dd29ec1f84ef2aad6a1efb385b93a","value":" 258/258 [00:00&lt;00:00, 4034.77 examples/s]"}},"d9582e8c264643e2a163718896e4a3fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e95b098a6534bf69b21afa562ec4d32":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7471550d17004e4a92c6e9cc60d8bfbd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"166db31ca4cc4fae993bfde156173c72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8d460300bf547f08802b12bf52d08ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ce6c5be64de84664a781aa79824af469":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"117dd29ec1f84ef2aad6a1efb385b93a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9207068,"sourceType":"datasetVersion","datasetId":5566933}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#**Step 1: Install All the Required Packages**","metadata":{"id":"q57Zf8p9ivZa"}},{"cell_type":"code","source":"!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.4.7","metadata":{"id":"GLXwJqbjtPho","colab":{"base_uri":"https://localhost:8080/"},"outputId":"74fd60be-9db6-4e25-a838-688ef681fc0e","execution":{"iopub.status.busy":"2024-09-21T11:18:08.959364Z","iopub.execute_input":"2024-09-21T11:18:08.959660Z","iopub.status.idle":"2024-09-21T11:18:46.409121Z","shell.execute_reply.started":"2024-09-21T11:18:08.959635Z","shell.execute_reply":"2024-09-21T11:18:46.408149Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.14.15 requires transformers>=4.33.1, but you have transformers 4.31.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"#**Step 2: Import All the Required Libraries**","metadata":{"id":"8vwn6xGIi03f"}},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import LoraConfig, PeftModel\nfrom trl import SFTTrainer","metadata":{"id":"nAMzy_0FtaUZ","execution":{"iopub.status.busy":"2024-09-21T11:18:46.411551Z","iopub.execute_input":"2024-09-21T11:18:46.412374Z","iopub.status.idle":"2024-09-21T11:19:18.839433Z","shell.execute_reply.started":"2024-09-21T11:18:46.412329Z","shell.execute_reply":"2024-09-21T11:19:18.838448Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-09-21 11:19:00.240803: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-09-21 11:19:00.240950: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-09-21 11:19:00.530385: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#**In case of Llama 2, the following prompt template is used for the chat models**","metadata":{"id":"J5d58CfLoWZj"}},{"cell_type":"markdown","source":"System Prompt (optional) to guide the model\n\n\nUser prompt (required) to give the instruction\n\n\nModel Answer (required)","metadata":{"id":"5lYYzhCRov5y"}},{"cell_type":"markdown","source":"![image.png](data:image/png;base64,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)","metadata":{"id":"AS1Ee8JunXgp"}},{"cell_type":"markdown","source":"#We will reformat our instruction dataset to follow Llama 2 template.","metadata":{"id":"ck708D51o-h3"}},{"cell_type":"markdown","source":"- Orignal Dataset: https://huggingface.co/datasets/timdettmers/openassistant-guanaco","metadata":{"id":"YS0zP2DKpJRY"}},{"cell_type":"markdown","source":"- Reformat Dataset following the Llama 2 template with 1k sample: https://huggingface.co/datasets/mlabonne/guanaco-llama2-1k","metadata":{"id":"DKzi2s6RpNdH"}},{"cell_type":"markdown","source":"- Complete Reformat Dataset following the Llama 2 template: https://huggingface.co/datasets/mlabonne/guanaco-llama2","metadata":{"id":"jVEAxq2piiyX"}},{"cell_type":"markdown","source":"To know how this dataset was created, you can check this notebook.  \n\nhttps://colab.research.google.com/drive/1Ad7a9zMmkxuXTOh1Z7-rNSICA4dybpM2?usp=sharing","metadata":{"id":"Cg_GnaVRrv8R"}},{"cell_type":"markdown","source":"### Note: You don’t need to follow a specific prompt template if you’re using the base Llama 2 model instead of the chat version.","metadata":{"id":"jSFfMkSpphFS"}},{"cell_type":"markdown","source":"#**How to fine tune Llama 2**","metadata":{"id":"zdcR5JHdp6qY"}},{"cell_type":"markdown","source":"- Free Google Colab offers a 15GB Graphics Card (Limited Resources --> Barely enough to store Llama 2–7b’s weights)","metadata":{"id":"FDEaxMxFqAV4"}},{"cell_type":"markdown","source":"- We also need to consider the overhead due to optimizer states, gradients, and forward activations","metadata":{"id":"rwJnbDU1qNx6"}},{"cell_type":"markdown","source":"- Full fine-tuning is not possible here: we need parameter-efficient fine-tuning (PEFT) techniques like LoRA or QLoRA.","metadata":{"id":"DIeTamzXqcC3"}},{"cell_type":"markdown","source":"- To drastically reduce the VRAM usage, we must fine-tune the model in 4-bit precision, which is why we’ll use QLoRA here.","metadata":{"id":"1lDdMCfyqvy2"}},{"cell_type":"markdown","source":"#**Step 3**","metadata":{"id":"8gXkTpnRq9nY"}},{"cell_type":"markdown","source":"1. Load a llama-2-7b-chat-hf model (chat model)\n2. Train it on the mlabonne/guanaco-llama2-1k (1,000 samples), which will produce our fine-tuned model Llama-2-7b-chat-finetune","metadata":{"id":"A3XhjPfHq_mw"}},{"cell_type":"markdown","source":"QLoRA will use a rank of 64 with a scaling parameter of 16. We’ll load the Llama 2 model directly in 4-bit precision using the NF4 type and train it for one epoch","metadata":{"id":"l6CPejEgv7hq"}},{"cell_type":"code","source":"# The model that you want to train from the Hugging Face hub\nmodel_name = \"meta-llama/Llama-2-7b-chat-hf\"\n\n# The instruction dataset to use\n# dataset_name = \"mlabonne/guanaco-llama2-1k\"\n\n# Fine-tuned model name\nnew_model = \"Llama-2-7b-chat-finetune\"\n\n################################################################################\n# QLoRA parameters\n################################################################################\n\n# LoRA attention dimension\nlora_r = 64\n\n# Alpha parameter for LoRA scaling\nlora_alpha = 16\n\n# Dropout probability for LoRA layers\nlora_dropout = 0.1\n\n################################################################################\n# bitsandbytes parameters\n################################################################################\n\n# Activate 4-bit precision base model loading\nuse_4bit = True\n\n# Compute dtype for 4-bit base models\nbnb_4bit_compute_dtype = \"float16\"\n\n# Quantization type (fp4 or nf4)\nbnb_4bit_quant_type = \"nf4\"\n\n# Activate nested quantization for 4-bit base models (double quantization)\nuse_nested_quant = False\n\n################################################################################\n# TrainingArguments parameters\n################################################################################\n\n# Output directory where the model predictions and checkpoints will be stored\noutput_dir = \"./results\"\n\n# Number of training epochs\nnum_train_epochs = 10\n\n# Enable fp16/bf16 training (set bf16 to True with an A100)\nfp16 = False\nbf16 = False\n\n# Batch size per GPU for training\nper_device_train_batch_size = 4\n\n# Batch size per GPU for evaluation\nper_device_eval_batch_size = 4\n\n# Number of update steps to accumulate the gradients for\ngradient_accumulation_steps = 1\n\n# Enable gradient checkpointing\ngradient_checkpointing = True\n\n# Maximum gradient normal (gradient clipping)\nmax_grad_norm = 0.3\n\n# Initial learning rate (AdamW optimizer)\nlearning_rate = 2e-4\n\n# Weight decay to apply to all layers except bias/LayerNorm weights\nweight_decay = 0.001\n\n# Optimizer to use\noptim = \"paged_adamw_32bit\"\n\n# Learning rate schedule\nlr_scheduler_type = \"cosine\"\n\n# Number of training steps (overrides num_train_epochs)\nmax_steps = -1\n\n# Ratio of steps for a linear warmup (from 0 to learning rate)\nwarmup_ratio = 0.03\n\n# Group sequences into batches with same length\n# Saves memory and speeds up training considerably\ngroup_by_length = True\n\n# Save checkpoint every X updates steps\nsave_steps = 0\n\n# Log every X updates steps\nlogging_steps = 25\n\n################################################################################\n# SFT parameters\n################################################################################\n\n# Maximum sequence length to use\nmax_seq_length = None\n\n# Pack multiple short examples in the same input sequence to increase efficiency\npacking = False\n\n# Load the entire model on the GPU 0\ndevice_map = {\"\": 0}","metadata":{"id":"ib_We3NLtj2E","execution":{"iopub.status.busy":"2024-09-21T11:19:18.840745Z","iopub.execute_input":"2024-09-21T11:19:18.841111Z","iopub.status.idle":"2024-09-21T11:19:18.854177Z","shell.execute_reply.started":"2024-09-21T11:19:18.841077Z","shell.execute_reply":"2024-09-21T11:19:18.853040Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#**Step 4:Load everything and start the fine-tuning process**","metadata":{"id":"G9w5Txi5wI2B"}},{"cell_type":"markdown","source":"1. First of all, we want to load the dataset we defined. Here, our dataset is already preprocessed but, usually, this is where you would reformat the prompt, filter out bad text, combine multiple datasets, etc.\n\n\n2. Then, we’re configuring bitsandbytes for 4-bit quantization.\n\n\n3. Next, we're loading the Llama 2 model in 4-bit precision on a GPU with the corresponding tokenizer.\n\n\n4. Finally, we're loading configurations for QLoRA, regular training parameters, and passing everything to the SFTTrainer. The training can finally start!","metadata":{"id":"qNx4Es23wjzC"}},{"cell_type":"code","source":"!pip install datasets -q","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"theG_rDJkPPg","outputId":"bf105ea7-1f19-4a58-853e-02087b75d406","execution":{"iopub.status.busy":"2024-09-21T11:19:18.856513Z","iopub.execute_input":"2024-09-21T11:19:18.856771Z","iopub.status.idle":"2024-09-21T11:19:31.401768Z","shell.execute_reply.started":"2024-09-21T11:19:18.856748Z","shell.execute_reply":"2024-09-21T11:19:31.400708Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"}]},{"cell_type":"code","source":"# for parsing csv source file\nimport csv\n\npath_to_csv_file = \"/kaggle/input/brooklyn99/filtered_jake_amy.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-09-21T11:19:31.403486Z","iopub.execute_input":"2024-09-21T11:19:31.404047Z","iopub.status.idle":"2024-09-21T11:19:31.409038Z","shell.execute_reply.started":"2024-09-21T11:19:31.404004Z","shell.execute_reply":"2024-09-21T11:19:31.408142Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# print(\"Parsing data...\")\n# rows_to_keep = []\n# with open(path_to_csv_file, encoding=\"utf-8-sig\") as f:\n#   reader = csv.DictReader(f, delimiter=\",\")\n#   last_row = None\n#   for row in reader:\n#     if \"JAKE\" == row[\"name\"] and last_row is not None:\n#       rows_to_keep.append(last_row)\n#       rows_to_keep.append(row)\n#       last_row = None\n#     else:\n#       last_row = row\n\n# # create a role-playing prompt for training and\n# # later for prompting\n# role_play_prompt = \"You're playing Jake Peralta, a brilliant but immature detective with a love for pop culture, especially Die Hard. He’s funny, quick-witted, and deeply loyal to his friends, but he also learns to balance his playful nature with the responsibilities of being a top-notch detective. Your role is to blend humor with moments of genuine heart and determination.\"\n\n# # combine pairs of rows from above to\n# # create prompt + reponse on each line\n# # using prompt template in 'lines' array\n# lines = []\n# for i in range(0, len(rows_to_keep), 2):\n#   prompt = rows_to_keep[i]\n#   response = rows_to_keep[i+1]\n#   start_str = f\"<s>### Instruction:\\n{role_play_prompt}\\n\\n###Input:\\n\"\n#   prompt = prompt[\"line\"].replace('\"','\\\\\"')\n#   mid_str = '''\\n\\n### Response:\\n'''\n#   response = response[\"line\"].replace('\"','\\\\\"')\n#   end_str = '''</s>'''\n#   total_line = start_str + prompt + mid_str + response + end_str\n#   # each line of training data is a simple object: 'inputs' and actual training string\n#   obj = {\n#     \"inputs\" : total_line\n#   }\n#   lines.append(obj)\n#   # print(total_line) # comment in to see how the formatted lines look\n#     # these lines could also be written to a jsonl file for use\n#     # with the command line interface\n# print(f\"Generated {len(lines)} lines to fine-tune\")\n# print(f\"Example training line: {lines[0]}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:47:38.327995Z","iopub.execute_input":"2024-09-21T09:47:38.328325Z","iopub.status.idle":"2024-09-21T09:47:38.390603Z","shell.execute_reply.started":"2024-09-21T09:47:38.328275Z","shell.execute_reply":"2024-09-21T09:47:38.389724Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Parsing data...\nGenerated 747 lines to fine-tune\nExample training line: {'inputs': \"<s>### Instruction:\\nYou're playing Jake Peralta, a brilliant but immature detective with a love for pop culture, especially Die Hard. He’s funny, quick-witted, and deeply loyal to his friends, but he also learns to balance his playful nature with the responsibilities of being a top-notch detective. Your role is to blend humor with moments of genuine heart and determination.\\n\\n###Input:\\n Hey! What are you doing, weirdo?\\n\\n### Response:\\n I'm doing the best speech from Donnie Brasco. Or actually, ten of me are doing the best speech from Donnie Brasco. [He stares at the screens of himself.] 'Sup?</s>\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"# from datasets import Dataset\n# dataset = Dataset.from_dict({\"text\": [item[\"inputs\"] for item in lines]})\n\n# # Display the number of records and the first record\n# print(f\"Generated {len(dataset)} records.\")\n# print(f\"Example record: {dataset[0]}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-21T09:47:38.391708Z","iopub.execute_input":"2024-09-21T09:47:38.391996Z","iopub.status.idle":"2024-09-21T09:47:38.409446Z","shell.execute_reply.started":"2024-09-21T09:47:38.391971Z","shell.execute_reply":"2024-09-21T09:47:38.408365Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Generated 747 records.\nExample record: {'text': \"<s>### Instruction:\\nYou're playing Jake Peralta, a brilliant but immature detective with a love for pop culture, especially Die Hard. He’s funny, quick-witted, and deeply loyal to his friends, but he also learns to balance his playful nature with the responsibilities of being a top-notch detective. Your role is to blend humor with moments of genuine heart and determination.\\n\\n###Input:\\n Hey! What are you doing, weirdo?\\n\\n### Response:\\n I'm doing the best speech from Donnie Brasco. Or actually, ten of me are doing the best speech from Donnie Brasco. [He stares at the screens of himself.] 'Sup?</s>\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"import csv\nfrom datasets import Dataset\n\n# Define the path to your CSV file\npath_to_csv_file = \"/kaggle/input/brooklyn99/filtered_jake_amy.csv\"\n\n# Role play prompt for Jake Peralta\nrole_play_prompt = (\n    \"You're playing Jake Peralta, a brilliant but immature detective with a love for pop culture, \"\n    \"especially Die Hard. He’s funny, quick-witted, and deeply loyal to his friends, but he also learns \"\n    \"to balance his playful nature with the responsibilities of being a top-notch detective. Your role is \"\n    \"to blend humor with moments of genuine heart and determination.\"\n)\n\n# Parse the CSV file and create a list of dictionaries with the formatted data\ndef parse_csv_to_dataset(csv_file_path):\n    rows_to_keep = []\n    with open(csv_file_path, encoding=\"utf-8-sig\") as f:\n        reader = csv.DictReader(f, delimiter=\",\")\n        last_row = None\n        for row in reader:\n            if \"JAKE\" == row[\"name\"] and last_row is not None:\n                rows_to_keep.append(last_row)\n                rows_to_keep.append(row)\n                last_row = None\n            else:\n                last_row = row\n    \n    data = []\n    for i in range(0, len(rows_to_keep), 2):\n        prompt = rows_to_keep[i][\"line\"].replace('\"','\\\\\"')\n        response = rows_to_keep[i+1][\"line\"].replace('\"','\\\\\"')\n        \n        formatted_text = (\n            f\"<s>[INST] <<SYS>>\\n{role_play_prompt}\\n\\n<</SYS>>\\n\"\n            f\"{prompt}\\n\\n[/INST]\\n{response}</s>\"\n        )\n        \n        data.append({\"text\": formatted_text})\n    \n    return data\n\n# Generate the data\nparsed_data = parse_csv_to_dataset(path_to_csv_file)\n\n# Create a Dataset object from the list of dictionaries\ndataset = Dataset.from_dict({\"text\": [item[\"text\"] for item in parsed_data]})\n\n# Display the number of records and the first record\nprint(f\"Generated {len(dataset)} records.\")\nprint(f\"Example record: {dataset[0]}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-21T12:34:54.774063Z","iopub.execute_input":"2024-09-21T12:34:54.774998Z","iopub.status.idle":"2024-09-21T12:34:54.826597Z","shell.execute_reply.started":"2024-09-21T12:34:54.774957Z","shell.execute_reply":"2024-09-21T12:34:54.825693Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Generated 747 records.\nExample record: {'text': \"<s>[INST] <<SYS>>\\nYou're playing Jake Peralta, a brilliant but immature detective with a love for pop culture, especially Die Hard. He’s funny, quick-witted, and deeply loyal to his friends, but he also learns to balance his playful nature with the responsibilities of being a top-notch detective. Your role is to blend humor with moments of genuine heart and determination.\\n\\n<</SYS>>\\n Hey! What are you doing, weirdo?\\n\\n[/INST]\\n I'm doing the best speech from Donnie Brasco. Or actually, ten of me are doing the best speech from Donnie Brasco. [He stares at the screens of himself.] 'Sup?</s>\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"print(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T12:34:58.557762Z","iopub.execute_input":"2024-09-21T12:34:58.558463Z","iopub.status.idle":"2024-09-21T12:34:58.563423Z","shell.execute_reply.started":"2024-09-21T12:34:58.558426Z","shell.execute_reply":"2024-09-21T12:34:58.562338Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['text'],\n    num_rows: 747\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset[246]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Q8-KPOCe2Ey","outputId":"c385b42b-0afd-4233-d0a1-bd2800cb6e2d","execution":{"iopub.status.busy":"2024-09-21T12:35:01.630309Z","iopub.execute_input":"2024-09-21T12:35:01.630686Z","iopub.status.idle":"2024-09-21T12:35:01.637112Z","shell.execute_reply.started":"2024-09-21T12:35:01.630656Z","shell.execute_reply":"2024-09-21T12:35:01.636147Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"{'text': \"<s>[INST] <<SYS>>\\nYou're playing Jake Peralta, a brilliant but immature detective with a love for pop culture, especially Die Hard. He’s funny, quick-witted, and deeply loyal to his friends, but he also learns to balance his playful nature with the responsibilities of being a top-notch detective. Your role is to blend humor with moments of genuine heart and determination.\\n\\n<</SYS>>\\n Yeah.\\n\\n[/INST]\\n Oh, Mrs. Dozerman, your husband was a great man. Some of my fondest memories of him were on our fishing trips.</s>\"}"},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5R96UTayo1S7","outputId":"04e8f31e-5187-4ad5-9e07-71a0bb9aa4f7","execution":{"iopub.status.busy":"2024-09-21T11:19:31.533617Z","iopub.execute_input":"2024-09-21T11:19:31.533892Z","iopub.status.idle":"2024-09-21T11:19:31.547046Z","shell.execute_reply.started":"2024-09-21T11:19:31.533850Z","shell.execute_reply":"2024-09-21T11:19:31.546163Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text'],\n    num_rows: 747\n})"},"metadata":{}}]},{"cell_type":"code","source":"# import csv\n# import json\n# from datasets import Dataset\n\n# # Path to your CSV file\n# csv_file_path = '/kaggle/input/brooklyn99/filtered_jake_amy.csv'\n\n# # Step 1: Prepare the data in the required format\n# conversations = []\n# current_conversation = \"\"\n\n# with open(csv_file_path, newline='', encoding='utf-8') as csvfile:\n#     reader = csv.reader(csvfile)\n#     next(reader)  # Skip header if present\n\n#     for row in reader:\n#         character, dialogue = row[0].strip().upper(), row[1].strip()\n\n#         if character == 'AMY':\n#             # Finalize current conversation (if any)\n#             if current_conversation:\n#                 conversations.append(current_conversation)\n#                 current_conversation = \"\"\n\n#             # Start new conversation with Amy first\n#             current_conversation = f\"[AMY]: {dialogue}\"\n\n#         elif character == 'JAKE' and current_conversation:\n#             # Add Jake's response after Amy in the same conversation\n#             current_conversation += f\"\\n[JAKE]: {dialogue}\"\n\n#         elif character == 'JAKE':\n#             # Start new conversation with Jake if Amy doesn't start the dialogue\n#             current_conversation = f\"[JAKE]: {dialogue}\"\n\n#     # Append the last conversation\n#     if current_conversation:\n#         conversations.append(current_conversation)\n\n# # Step 2: Create a Hugging Face Dataset from the conversations\n# # Each entry is treated as a single \"text\" feature\n# dataset = Dataset.from_dict({\"text\": conversations})\n\n# # Step 3: Display the Dataset summary\n# print(dataset)\n\n# # Optional: Save the dataset for later use\n# dataset.save_to_disk('path_to_save_dataset')\n\n# # Example: Output the number of rows (num_rows)\n# print(f\"Number of rows: {dataset.num_rows}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-21T11:36:41.441409Z","iopub.execute_input":"2024-09-21T11:36:41.442034Z","iopub.status.idle":"2024-09-21T11:36:41.484752Z","shell.execute_reply.started":"2024-09-21T11:36:41.442000Z","shell.execute_reply":"2024-09-21T11:36:41.483930Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['text'],\n    num_rows: 502\n})\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/502 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3882bc7699547f6b8955812035adf1b"}},"metadata":{}},{"name":"stdout","text":"Number of rows: 502\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\n\n# Replace 'your_huggingface_api_key' with your actual API key\napi_key = \"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\"\n\n# Login using the API key\nlogin(token=api_key)\n\nprint(\"Successfully logged in to Hugging Face!\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-21T12:35:05.930313Z","iopub.execute_input":"2024-09-21T12:35:05.930677Z","iopub.status.idle":"2024-09-21T12:35:06.028415Z","shell.execute_reply.started":"2024-09-21T12:35:05.930648Z","shell.execute_reply":"2024-09-21T12:35:06.027524Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\nSuccessfully logged in to Hugging Face!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load dataset (you can process it here)\n# dataset = load_dataset(dataset_name, split=\"train\")\n\n# Load tokenizer and model with QLoRA configuration\ncompute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=use_4bit,\n    bnb_4bit_quant_type=bnb_4bit_quant_type,\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=use_nested_quant,\n)\n\n# Check GPU compatibility with bfloat16\nif compute_dtype == torch.float16 and use_4bit:\n    major, _ = torch.cuda.get_device_capability()\n    if major >= 8:\n        print(\"=\" * 80)\n        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n        print(\"=\" * 80)\n\n# Load base model\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=device_map,\n    use_auth_token=True  # Added here\n)\n\n# model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\n# Load LLaMA tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\n    model_name,\n    trust_remote_code=True,\n    use_auth_token=True  # Added here\n)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training\n\n# Load LoRA configuration\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_r,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\n# Set training parameters\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    fp16=fp16,\n    bf16=bf16,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=group_by_length,\n    lr_scheduler_type=lr_scheduler_type,\n    report_to=\"tensorboard\"\n)\n\n# Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    max_seq_length=max_seq_length,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=packing,\n)\n\n# Train model\ntrainer.train()\n","metadata":{"id":"OJXpOgBFuSrc","colab":{"base_uri":"https://localhost:8080/","height":997,"referenced_widgets":["9a4d3ebef9824382a735af06ebec0e84","4bb0d453f5f54c709b5514d682fe1bd1","869798cf28d2456fbce931fa9bd64512","81231c95170d47adac2086110c27c5b2","bbde9c9273624346a412e04e680473cd","c02773f7a28e4fcd928f526d068c0362","353bbfa82f494d3ea4f4dbf1cc689150","329632d9047e455fa673d15a0270987a","e84a683dbb7f4e00831a28e337552c3e","32d345c90f8747d3b8d7b1431e8568ac","f9318e9b3c594b80a4e8eb805cb5d1c2","535b5c4819374d2d897aae06d3a6e17e","076758d6cbd143659c6c8ab6313cf24f","f710a18db1df40d1b7174614953570cb","ca7a5575976f4c7baf9f0eaec0cba4ce","5fc2b4922b1d413698e9cbe306018892","4547a6b2150d4e2dbd90fc0f9654286c","e9351e66c1234a32b16455cf8fdc7787","ef99c1bd2fbe405c9508aea879e83a53","e2f9c498b9324d72b8b492c5f811c9e6","649be54afb1f4c01a04ddf83506fcf21","69cf611572b74448afcbeec773bebd3c"]},"outputId":"c4eac15c-dba7-45b7-c19a-09345c080722","execution":{"iopub.status.busy":"2024-09-21T12:35:07.885477Z","iopub.execute_input":"2024-09-21T12:35:07.885841Z","iopub.status.idle":"2024-09-21T13:57:20.091089Z","shell.execute_reply.started":"2024-09-21T12:35:07.885809Z","shell.execute_reply":"2024-09-21T13:57:20.090176Z"},"trusted":true},"execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e57c38db064433aa6e12eef51feb735"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/747 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ded34cde0214679ba62b502d0a58128"}},"metadata":{}},{"name":"stdout","text":"{'loss': 3.0601, 'learning_rate': 0.00017241379310344826, 'epoch': 0.27}\n{'loss': 1.1419, 'learning_rate': 0.0001997378910967147, 'epoch': 0.53}\n{'loss': 0.7326, 'learning_rate': 0.0001987444391808659, 'epoch': 0.8}\n{'loss': 0.6927, 'learning_rate': 0.00019701751002259448, 'epoch': 1.06}\n{'loss': 0.6777, 'learning_rate': 0.0001945699313137419, 'epoch': 1.33}\n{'loss': 0.6673, 'learning_rate': 0.00019141988375690646, 'epoch': 1.6}\n{'loss': 0.6882, 'learning_rate': 0.00018759076601853106, 'epoch': 1.86}\n{'loss': 0.6699, 'learning_rate': 0.00018311102092276815, 'epoch': 2.13}\n{'loss': 0.6261, 'learning_rate': 0.0001780139241771599, 'epoch': 2.39}\n{'loss': 0.6495, 'learning_rate': 0.0001723373371994869, 'epoch': 2.66}\n{'loss': 0.6272, 'learning_rate': 0.00016612342588179617, 'epoch': 2.93}\n{'loss': 0.6033, 'learning_rate': 0.00015941834738064024, 'epoch': 3.19}\n{'loss': 0.5707, 'learning_rate': 0.00015227190726005953, 'epoch': 3.46}\n{'loss': 0.6095, 'learning_rate': 0.00014473718953406296, 'epoch': 3.72}\n{'loss': 0.5926, 'learning_rate': 0.00013687016235666447, 'epoch': 3.99}\n{'loss': 0.6187, 'learning_rate': 0.00012872926228842398, 'epoch': 4.26}\n{'loss': 0.5701, 'learning_rate': 0.00012037496022757552, 'epoch': 4.52}\n{'loss': 0.5851, 'learning_rate': 0.00011186931223002255, 'epoch': 4.79}\n{'loss': 0.5221, 'learning_rate': 0.00010327549855472455, 'epoch': 5.05}\n{'loss': 0.5047, 'learning_rate': 9.465735435846348e-05, 'epoch': 5.32}\n{'loss': 0.5363, 'learning_rate': 8.607889552600524e-05, 'epoch': 5.59}\n{'loss': 0.5356, 'learning_rate': 7.760384315780731e-05, 'epoch': 5.85}\n{'loss': 0.5019, 'learning_rate': 6.9295150247395e-05, 'epoch': 6.12}\n{'loss': 0.4636, 'learning_rate': 6.121453406426341e-05, 'epoch': 6.38}\n{'loss': 0.4518, 'learning_rate': 5.3422017715781856e-05, 'epoch': 6.65}\n{'loss': 0.4728, 'learning_rate': 4.5975484293395696e-05, 'epoch': 6.91}\n{'loss': 0.4139, 'learning_rate': 3.893024691494279e-05, 'epoch': 7.18}\n{'loss': 0.4161, 'learning_rate': 3.2338637856827145e-05, 'epoch': 7.45}\n{'loss': 0.4227, 'learning_rate': 2.6249619827988915e-05, 'epoch': 7.71}\n{'loss': 0.4148, 'learning_rate': 2.070842227314317e-05, 'epoch': 7.98}\n{'loss': 0.4076, 'learning_rate': 1.5756205406839364e-05, 'epoch': 8.24}\n{'loss': 0.4171, 'learning_rate': 1.1429754473908538e-05, 'epoch': 8.51}\n{'loss': 0.4248, 'learning_rate': 7.761206507343044e-06, 'epoch': 8.78}\n{'loss': 0.3936, 'learning_rate': 4.777811613260574e-06, 'epoch': 9.04}\n{'loss': 0.3981, 'learning_rate': 2.501730556136783e-06, 'epoch': 9.31}\n{'loss': 0.4141, 'learning_rate': 9.498701478504845e-07, 'epoch': 9.57}\n{'loss': 0.3752, 'learning_rate': 1.337576632774784e-07, 'epoch': 9.84}\n{'train_runtime': 4913.3876, 'train_samples_per_second': 1.52, 'train_steps_per_second': 0.191, 'train_loss': 0.6123775870242018, 'epoch': 10.0}\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=940, training_loss=0.6123775870242018, metrics={'train_runtime': 4913.3876, 'train_samples_per_second': 1.52, 'train_steps_per_second': 0.191, 'train_loss': 0.6123775870242018, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"dataset[232]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GeUGmOpXecO4","outputId":"842f8202-42e9-49b1-dbf7-a5854c1c45ac","execution":{"iopub.status.busy":"2024-09-21T14:10:34.066292Z","iopub.execute_input":"2024-09-21T14:10:34.066973Z","iopub.status.idle":"2024-09-21T14:10:34.073498Z","shell.execute_reply.started":"2024-09-21T14:10:34.066937Z","shell.execute_reply":"2024-09-21T14:10:34.072610Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"{'text': \"<s>[INST] <<SYS>>\\nYou're playing Jake Peralta, a brilliant but immature detective with a love for pop culture, especially Die Hard. He’s funny, quick-witted, and deeply loyal to his friends, but he also learns to balance his playful nature with the responsibilities of being a top-notch detective. Your role is to blend humor with moments of genuine heart and determination.\\n\\n<</SYS>>\\n No, we're gonna secretly record the Vulture telling you to dump me. Then we'll play it for Chief Garmin. Then— \\n\\n[/INST]\\n We're gonna totally have sex on top of each other.</s>\"}"},"metadata":{}}]},{"cell_type":"code","source":"# Save trained model\ntrainer.model.save_pretrained(new_model)","metadata":{"id":"aQNaFYp40M6k","execution":{"iopub.status.busy":"2024-09-21T14:10:36.571939Z","iopub.execute_input":"2024-09-21T14:10:36.572322Z","iopub.status.idle":"2024-09-21T14:10:36.888220Z","shell.execute_reply.started":"2024-09-21T14:10:36.572293Z","shell.execute_reply":"2024-09-21T14:10:36.887263Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"##**Step 5: Check the plots on tensorboard, as follows**","metadata":{"id":"NBtXo_Tgw43o"}},{"cell_type":"markdown","source":"###**Step 6:Use the text generation pipeline to ask questions like “What is a large language model?” Note that I’m formatting the input to match Llama 2 prompt template.**","metadata":{"id":"TDqxnjvExGG6"}},{"cell_type":"code","source":"# Ignore warnings\nlogging.set_verbosity(logging.CRITICAL)\n\n# Run text generation pipeline with our next model\nprompt = \"Who are you?\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=80)\nresult = pipe(f\"<s>[INST] {prompt} [/INST]\")\nprint(result[0]['generated_text'])","metadata":{"id":"frlSLPin4IJ4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9b244b82-c976-4fa4-d8e7-5c393eba774a","execution":{"iopub.status.busy":"2024-09-21T13:57:20.430993Z","iopub.execute_input":"2024-09-21T13:57:20.431258Z","iopub.status.idle":"2024-09-21T13:57:36.049112Z","shell.execute_reply.started":"2024-09-21T13:57:20.431236Z","shell.execute_reply":"2024-09-21T13:57:36.048166Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"<s>[INST] Who is Amy? [/INST]  Amy is a character in the story. obviously, she’s not a real person, but rather a character in a story. The story is about a man named Jake, who is in love with his co-worker, Amy. Jake buys Amy a gift, but he accidentally puts it in the wrong office.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Ignore warnings\nlogging.set_verbosity(logging.CRITICAL)\n\n# Run text generation pipeline with our next model\nprompt = \"Hi jake\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=80)\nresult = pipe(f\"<s>[INST] {prompt} [/INST]\")\nprint(result[0]['generated_text'])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e1BeJdZgzZnB","outputId":"7e33b48b-1362-4784-b6ab-81328e1d8cb8","execution":{"iopub.status.busy":"2024-09-21T14:27:15.911766Z","iopub.execute_input":"2024-09-21T14:27:15.912223Z","iopub.status.idle":"2024-09-21T14:27:30.816107Z","shell.execute_reply.started":"2024-09-21T14:27:15.912190Z","shell.execute_reply":"2024-09-21T14:27:30.815212Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"<s>[INST] Hi jake [/INST]\n everybody's saying you're gonna be president one day.\n\n[/INST]\n I don't know if that's true, but I do know that I'm going to be a great athlete. I'm going to run the fastest mile on this team.\n\n[INST]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import pipeline, logging\n\n# Ignore warnings\nlogging.set_verbosity(logging.CRITICAL)\n\n# Properly formatted prompt\nprompt = \"Hi Jake?\"\nrole_play_prompt = (\n    \"You're playing Jake Peralta, a brilliant but immature detective with a love for pop culture, \"\n    \"especially Die Hard. He’s funny, quick-witted, and deeply loyal to his friends, but he also learns \"\n    \"to balance his playful nature with the responsibilities of being a top-notch detective. Your role is \"\n    \"to blend humor with moments of genuine heart and determination.\"\n)\n\n# Complete formatted input\nformatted_input = f\"<s>[INST] <<SYS>>\\n{role_play_prompt}\\n<</SYS>>\\n{prompt} [/INST]\"\n\n# Tokenize the input\ninput_ids = tokenizer.encode(formatted_input, return_tensors=\"pt\")\n\n# Generate text using your fine-tuned model\noutput_ids = model.generate(input_ids, max_length=100)\n\n# Decode the generated text to human-readable form\ngenerated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n\n# Output the generated text\nprint(generated_text)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ENjEgYsrz0Vo","outputId":"e03d843d-cb4a-4a98-a322-75c40dd7d979","execution":{"iopub.status.busy":"2024-09-21T12:30:35.304286Z","iopub.execute_input":"2024-09-21T12:30:35.304587Z","iopub.status.idle":"2024-09-21T12:30:35.651421Z","shell.execute_reply.started":"2024-09-21T12:30:35.304561Z","shell.execute_reply":"2024-09-21T12:30:35.650516Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[INST] <<SYS>>\nYou're playing Jake Peralta, a brilliant but immature detective with a love for pop culture, especially Die Hard. He’s funny, quick-witted, and deeply loyal to his friends, but he also learns to balance his playful nature with the responsibilities of being a top-notch detective. Your role is to blend humor with moments of genuine heart and determination.\n<</SYS>>\nHi Jake? [/INST] \n","output_type":"stream"}]},{"cell_type":"code","source":"# Use a pipeline as a high-level helper\nfrom transformers import pipeline\n\nformatted_input = f\"<s>[INST] <<SYS>>\\n{role_play_prompt}\\n<</SYS>>\\n{prompt} [/INST] ###Response\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=80)\npipe(formatted_input)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T12:31:12.964456Z","iopub.execute_input":"2024-09-21T12:31:12.965385Z","iopub.status.idle":"2024-09-21T12:31:13.281537Z","shell.execute_reply.started":"2024-09-21T12:31:12.965343Z","shell.execute_reply":"2024-09-21T12:31:13.280609Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': \"<s>[INST] <<SYS>>\\nYou're playing Jake Peralta, a brilliant but immature detective with a love for pop culture, especially Die Hard. He’s funny, quick-witted, and deeply loyal to his friends, but he also learns to balance his playful nature with the responsibilities of being a top-notch detective. Your role is to blend humor with moments of genuine heart and determination.\\n<</SYS>>\\nHi Jake? [/INST] ###Response\\n\"}]"},"metadata":{}}]},{"cell_type":"code","source":"# Ignore warnings\nlogging.set_verbosity(logging.CRITICAL)\n\n# Run text generation pipeline with our next model\nprompt = \"What happened in over 16 ball 6 in the match between Afghanistan and England?\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=100)\nresult = pipe(f\"<s>[INST] {prompt} [/INST]\")\nprint(result[0]['generated_text'])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9M3LxKI40FP1","outputId":"cd09ef4b-3323-4b15-d86c-21b8a2a2fdf2","execution":{"iopub.status.busy":"2024-09-21T12:31:14.808286Z","iopub.execute_input":"2024-09-21T12:31:14.809037Z","iopub.status.idle":"2024-09-21T12:31:32.562763Z","shell.execute_reply.started":"2024-09-21T12:31:14.809000Z","shell.execute_reply":"2024-09-21T12:31:32.561793Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"<s>[INST] What happened in over 16 ball 6 in the match between Afghanistan and England? [/INST]  I'm not sure what you're asking.\n[JAKE] Oh, man, I'm so sorry. I'm a little distracted. Sorry, everyone.\n[JAKE] Okay, so we're in the middle of a war, and we're not sure if we're gonna win\n","output_type":"stream"}]},{"cell_type":"code","source":"# Empty VRAM\ndel model\ndel pipe\ndel trainer\nimport gc\ngc.collect()\ngc.collect()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mkQCviG0Zta-","outputId":"8f4c5973-7442-4cae-8f33-bdc8c2b9b09b","execution":{"iopub.status.busy":"2024-09-21T09:47:39.056799Z","iopub.status.idle":"2024-09-21T09:47:39.057349Z","shell.execute_reply.started":"2024-09-21T09:47:39.057041Z","shell.execute_reply":"2024-09-21T09:47:39.057062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can train a Llama 2 model on the entire dataset using [mlabonne/guanaco-llama2](https://huggingface.co/datasets/mlabonne/guanaco-llama2)","metadata":{"id":"Ly6QcnNRxfNR"}},{"cell_type":"markdown","source":"#**Step 7: Store New Llama2 Model (Llama-2-7b-chat-finetune)**","metadata":{"id":"CwbthYYhxs8p"}},{"cell_type":"markdown","source":"How can we store our new Llama-2-7b-chat-finetune model now? We need to merge the weights from LoRA with the base model. Unfortunately, as far as I know, there is no straightforward way to do it: we need to reload the base model in FP16 precision and use the peft library to merge everything.","metadata":{"id":"ugs6EbD9xtAs"}},{"cell_type":"code","source":"# Reload model in FP16 and merge it with LoRA weights\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    low_cpu_mem_usage=True,\n    return_dict=True,\n    torch_dtype=torch.float16,\n    device_map=device_map,\n)\nmodel = PeftModel.from_pretrained(base_model, new_model)\nmodel = model.merge_and_unload()\n\n# Reload tokenizer to save it\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"","metadata":{"id":"QQn30cRtAZ-P","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["1751b6ecc16a4fb4868c3bc220aa58ea","201760115afc4573a7a13367781c7d6f","1ab579f2fc8d4407b022ae7c80a9bf53","2652d06548fe46958f77302ed3d64d91","7147e7131f3349ef934e531703759a98","716f9f452193463dbc5897c92689b346","9ae5b7f451804da2bc4c4720493f6c5a","792eb627c0e94492b940a5d011963fe5","25f97933aad94586b99364758a9dc7cd","664773f6c920486c8497147c132c224b","641f2a3f898a4402a1ef5216da911317"]},"outputId":"4fe7518f-69c4-43f6-8bd6-25532e143255","execution":{"iopub.status.busy":"2024-09-21T09:47:39.058754Z","iopub.status.idle":"2024-09-21T09:47:39.059216Z","shell.execute_reply.started":"2024-09-21T09:47:39.058972Z","shell.execute_reply":"2024-09-21T09:47:39.058991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#**Step 8: Push Model to Hugging Face Hub**","metadata":{"id":"2bn7tjdByJ_i"}},{"cell_type":"markdown","source":"Our weights are merged and we reloaded the tokenizer. We can now push everything to the Hugging Face Hub to save our model.","metadata":{"id":"CpyMDvc5yQrp"}},{"cell_type":"code","source":"import locale\nlocale.getpreferredencoding = lambda: \"UTF-8\"","metadata":{"id":"Z8VUygTdqVnJ","execution":{"iopub.status.busy":"2024-09-21T09:47:39.060805Z","iopub.status.idle":"2024-09-21T09:47:39.061294Z","shell.execute_reply.started":"2024-09-21T09:47:39.061035Z","shell.execute_reply":"2024-09-21T09:47:39.061055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login\n\nmodel.push_to_hub(\"entbappy/Llama-2-7b-chat-finetune\", check_pr=True)\n\ntokenizer.push_to_hub(\"entbappy/Llama-2-7b-chat-finetune\",check_pr=True)\n","metadata":{"id":"x-xPb-_qB0dz","colab":{"base_uri":"https://localhost:8080/","height":530,"referenced_widgets":["967f506f67784aa8854f3930dd8a942f","4f4636029a3041f6a2730c86b050b176","834f7c0110e14273923d69eea3eaaa6b","9b36aa3b4b0b47d98021224f832df7e3","c890a9a4f8e14c338f70c9a1894d57ec","2483174f0270429baa6686719ff82db6","be4b94a5be954b80afe07cc4b7692e62","6cf14735b7934b19ab7405810fa45d6e","e8cd2b521861457681ccc4bfc80101fa","8fc257c8ec1049eb9422069c3b00422c","d7435d16ee404031aae8c59d0df73980","0f54d458f9ca450383b01373539c2929","d59b25f9519640a28dda22056558f85a","e2b667d720444c189d4e9966898ae700","4e2f769a79e74f7baf41e0388838117e","09452cff173f45fe9e147acec344f71f","5ffb63e6404844e29cd82163f1231042","2eb48c542db94fa3ac11575750907684","4b77b066a7e946b0b210b73658c58656","d19bd27c95d54ef7a501c550065faafa","803ac263f7724e3db3ebf2ff75a9c7ef","bcfc173c770943ebb12f9e8403edda8a","e6ea7efc6e4c4ff9bc3916e80ae8e484","a9165b4ae2ba45f6b232f640b864addf","f3b3c49aff434a08a8d84fd91f21a243","3f73f7a6d1d74f3ab85dc5be08dbd9ea","5316ff5e03574e609e989a7343b5d985","9971ee52aa104344b9e0fb4d6027ea48","5d8eb62fdbc14bd8b84ada150f3c4c17","8c49f4a02322488cb1455b8759b78587","431e63c57b8a48d0a443f7264ffcd12a","e8394aae7eec4eb88b273e6a9ebe2627","5228c61bb6cf47ad9ae01b9ae5e424b2"]},"outputId":"86ddd0cb-4818-495d-e5db-ecac7917b86b","execution":{"iopub.status.busy":"2024-09-21T09:47:39.063391Z","iopub.status.idle":"2024-09-21T09:47:39.063693Z","shell.execute_reply.started":"2024-09-21T09:47:39.063544Z","shell.execute_reply":"2024-09-21T09:47:39.063557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"You can now use this model for inference by loading it like any other Llama 2 model from the Hub.","metadata":{"id":"6nxb3tkLyXeI"}},{"cell_type":"code","source":"import json\nfrom datasets import Dataset, DatasetDict\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\nfrom peft import LoraConfig\nfrom trl import SFTTrainer\n# from bitsandbytes import BitsAndBytesConfig\n\n# The model that you want to train from the Hugging Face hub\nmodel_name = \"NousResearch/Llama-2-7b-chat-hf\"\n\n# The instruction dataset to use\ndataset_name = \"mlabonne/guanaco-llama2-1k\"\n\n# Fine-tuned model name\nnew_model = \"Llama-2-7b-chat-finetune\"\n\n################################################################################\n# QLoRA parameters\n################################################################################\n\n# LoRA attention dimension\nlora_r = 64\n\n# Alpha parameter for LoRA scaling\nlora_alpha = 16\n\n# Dropout probability for LoRA layers\nlora_dropout = 0.1\n\n################################################################################\n# bitsandbytes parameters\n################################################################################\n\n# Activate 4-bit precision base model loading\nuse_4bit = True\n\n# Compute dtype for 4-bit base models\nbnb_4bit_compute_dtype = \"float16\"\n\n# Quantization type (fp4 or nf4)\nbnb_4bit_quant_type = \"nf4\"\n\n# Activate nested quantization for 4-bit base models (double quantization)\nuse_nested_quant = False\n\n################################################################################\n# TrainingArguments parameters\n################################################################################\n\n# Output directory where the model predictions and checkpoints will be stored\noutput_dir = \"./results\"\n\n# Number of training epochs\nnum_train_epochs = 10\n\n# Enable fp16/bf16 training (set bf16 to True with an A100)\nfp16 = False\nbf16 = False\n\n# Batch size per GPU for training\nper_device_train_batch_size = 4\n\n# Batch size per GPU for evaluation\nper_device_eval_batch_size = 4\n\n# Number of update steps to accumulate the gradients for\ngradient_accumulation_steps = 1\n\n# Enable gradient checkpointing\ngradient_checkpointing = True\n\n# Maximum gradient normal (gradient clipping)\nmax_grad_norm = 0.3\n\n# Initial learning rate (AdamW optimizer)\nlearning_rate = 2e-4\n\n# Weight decay to apply to all layers except bias/LayerNorm weights\nweight_decay = 0.001\n\n# Optimizer to use\noptim = \"paged_adamw_32bit\"\n\n# Learning rate schedule\nlr_scheduler_type = \"cosine\"\n\n# Number of training steps (overrides num_train_epochs)\nmax_steps = -1\n\n# Ratio of steps for a linear warmup (from 0 to learning rate)\nwarmup_ratio = 0.03\n\n# Group sequences into batches with same length\n# Saves memory and speeds up training considerably\ngroup_by_length = True\n\n# Save checkpoint every X updates steps\nsave_steps = 0\n\n# Log every X updates steps\nlogging_steps = 25\n\n################################################################################\n# SFT parameters\n################################################################################\n\n# Maximum sequence length to use\nmax_seq_length = None\n\n# Pack multiple short examples in the same input sequence to increase efficiency\npacking = False\n\n# Load the entire model on the GPU 0\ndevice_map = {\"\": 0}\n\n# Load the JSON file\nwith open(\"/content/951351.json\", 'r') as file:\n    cricket_data = json.load(file)\n\n# Extract match information\nteam1, team2 = cricket_data['info']['teams']\nvenue = cricket_data['info']['venue']\numpires = \", \".join(cricket_data['info']['officials']['umpires'])\ntoss_winner = cricket_data['info']['toss']['winner']\ntoss_decision = cricket_data['info']['toss']['decision']\noutcome = cricket_data['info']['outcome']\nwinner = outcome.get('winner', 'No result')\nwin_by = outcome['by'] if 'by' in outcome else 'No specific win method'\nmatch_type = cricket_data['info']['match_type']\nevent_name = cricket_data['info']['event']['name']\n\n# Create match information examples\nmatch_info_examples = [\n    {\"input\": \"Match venue\", \"output\": venue},\n    {\"input\": \"Teams playing\", \"output\": f\"{team1} vs {team2}\"},\n    {\"input\": \"Umpires\", \"output\": umpires},\n    {\"input\": \"Toss winner\", \"output\": toss_winner},\n    {\"input\": \"Toss decision\", \"output\": toss_decision},\n    {\"input\": \"Match outcome\", \"output\": f\"{winner} won by {win_by}\"},\n    {\"input\": \"Match type\", \"output\": match_type},\n    {\"input\": \"Event name\", \"output\": event_name}\n]\n\n# Create a list to store the examples with over and ball information\nexamples = match_info_examples.copy()\n\n# Process the JSON data to extract relevant information\nfor inning in cricket_data['innings']:\n    inning_name = list(inning.keys())[0]\n    inning_data = inning[inning_name]\n    inning_runs = 0\n    inning_wickets = 0\n\n    for over in inning['overs']:\n        over_number = over['over']\n        for ball_number, delivery in enumerate(over['deliveries'], start=1):\n            batter = delivery['batter']\n            bowler = delivery['bowler']\n            runs = delivery['runs']['total']\n            extras = delivery.get('extras', {})\n            extras_info = \", \".join([f\"{key}: {value}\" for key, value in extras.items()])\n\n            # Accumulate runs and check for wickets\n            inning_runs += runs\n            wicket_info = \"\"\n            if 'wickets' in delivery:\n                for wicket in delivery['wickets']:\n                    inning_wickets += 1\n                    player_out = wicket['player_out']\n                    kind = wicket['kind']\n                    fielders = \", \".join([fielder['name'] for fielder in wicket.get('fielders', [])])\n                    if kind == \"bowled\":\n                        wicket_info = f\"{player_out} was {kind} by {bowler}\"\n                    else:\n                        wicket_info = f\"{player_out} was {kind} by {fielders}\" if fielders else f\"{player_out} was {kind}\"\n\n            # Format the input and output\n            input_text = f\"In over {over_number}, ball {ball_number}\"\n            output_text = f\"{batter} faced {bowler} and scored {runs} run(s). {'Extras: ' + extras_info if extras_info else ''} {wicket_info if wicket_info else ''}\"\n\n            # Append to examples\n            examples.append({\"input\": input_text, \"output\": output_text})\n\n    # Add innings summary information at the end of each inning\n    inning_summary_input = f\"{inning_name} summary\"\n    inning_summary_output = f\"Total runs scored: {inning_runs}, Total wickets taken: {inning_wickets}.\"\n    examples.append({\"input\": inning_summary_input, \"output\": inning_summary_output})\n\n# Create Dataset\ndataset = Dataset.from_dict({'input': [example['input'] for example in examples], 'output': [example['output'] for example in examples]})\n\n# Print column names and some examples\nprint(dataset.column_names)  # Output: ['input', 'output']\nprint(dataset[:5])  # Output first 5 examples\n\n# Save the dataset to disk if needed\ndataset.save_to_disk('cricket')\n\n# Load tokenizer and model with QLoRA configuration\ncompute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=use_4bit,\n    bnb_4bit_quant_type=bnb_4bit_quant_type,\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=use_nested_quant,\n)\n\n# Check GPU compatibility with bfloat16\nif compute_dtype == torch.float16 and use_4bit:\n    major, _ = torch.cuda.get_device_capability()\n    if major >= 8:\n        print(\"=\" * 80)\n        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n        print(\"=\" * 80)\n\n# Load base model\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=device_map\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\n# Load LLaMA tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training\n\n# Load LoRA configuration\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    # r=r,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\n# Set training parameters\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=num_train_epochs,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    weight_decay=weight_decay,\n    fp16=fp16,\n    bf16=bf16,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=group_by_length,\n    lr_scheduler_type=lr_scheduler_type,\n    report_to=\"tensorboard\"\n)\n\n# Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"output\",\n    max_seq_length=max_seq_length,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=packing,\n)\n\n# Train model\ntrainer.train()\n","metadata":{"id":"UwfgUuy_ppsZ","colab":{"base_uri":"https://localhost:8080/","height":371,"referenced_widgets":["4a4522c471494de5b808c5dc0f46857a","85b350c17912470aa8089c84b2830de9","8cd4ddfc3c5442ad97e952299ab80fa3","ec9c8ec487024b22a66131a6c5fa8f08","88ccc7ea62464d6987b205e135040144","c42e25104c85432e954f96761194d6ea","dc2b4dfa085f4863b2d5bcaec0020e6c","d03ad70643694744b2b42dfa59d94976","c839f66b518b42b4897f09b103d77af3","106ef8bc620d4e168b1dc9f8a0e5ed38","ce0b2cbea5af4869b0a9565fd1d02a38","0098d4ba06534ae987034459a6dc38b2","0647d3baae61493e801feb5db1a6e768","bf64c7b37ec74a5a8aa49227bd36f28c","5b235119d1864c20925f680810f2b217","89fb2ca45d4e431590db1c0683e85d4d","d8437ba15f234403a218116f5a3f6390","fe1f505484af42b6ae4b90b938ba9cc5","88dcee36007d4cf7b768228be952e26f","17a48c1a34da4ff49c975e97e8e9b332","7445003d60a74aecac67d707121c2119","ba77a9eb5ac74c87acf64b9eedbd9c8d","ab7bebbafd4645b8920a47f7c9fe90e3","a31ba472ddaa44d18b8c530214ef6047","236b9d6ff3d94239b07eec49387d7483","8de106bd564b4a548c95453992e8b035","d9582e8c264643e2a163718896e4a3fb","3e95b098a6534bf69b21afa562ec4d32","7471550d17004e4a92c6e9cc60d8bfbd","166db31ca4cc4fae993bfde156173c72","b8d460300bf547f08802b12bf52d08ec","ce6c5be64de84664a781aa79824af469","117dd29ec1f84ef2aad6a1efb385b93a"]},"outputId":"bbe56576-cd3a-44b4-cc1d-dcada5bcb2b2","execution":{"iopub.status.busy":"2024-09-21T09:47:39.065024Z","iopub.status.idle":"2024-09-21T09:47:39.065445Z","shell.execute_reply.started":"2024-09-21T09:47:39.065221Z","shell.execute_reply":"2024-09-21T09:47:39.065237Z"},"trusted":true},"execution_count":null,"outputs":[]}]}